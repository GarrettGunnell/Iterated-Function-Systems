#pragma kernel SingleThreadedScan
#pragma kernel GlobalReduce
#pragma kernel FinalReduce

RWStructuredBuffer<float3> _OutputBuffer, _InputBuffer;
uint _ReductionBufferSize;

[numthreads(1, 1, 1)]
void SingleThreadedScan(uint3 id : SV_DISPATCHTHREADID) {
    float3 minPos = 1000000000000000.0f;
    float3 maxPos = -1000000000000000.0f;

    for (uint i = 0; i < _ReductionBufferSize; ++i) {
        float3 v = _InputBuffer[i];

        minPos = min(minPos, v);
        maxPos = max(maxPos, v);
    }

    if (id.x == 0) {
        _OutputBuffer[0] = minPos;
        _OutputBuffer[1] = maxPos;
    }
}


// Reduction kernels and optimization progression referenced from https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf

#pragma multi_compile_local _ INTERLEAVED_ADDRESSING_DIVERGENT INTERLEAVED_ADDRESSING_BANK_CONFLICT SEQUENTIAL_ADDRESSING
#pragma multi_compile_local _ DOUBLE_LOAD
#pragma multi_compile_local _ MIN_REDUCTION MAX_REDUCTION

#define REDUCTION_GROUP_SIZE 128


groupshared float3 gs_Reduce[REDUCTION_GROUP_SIZE];

float3 ReductionOperator(float3 v1, float3 v2) {
#ifdef MIN_REDUCTION
        return min(v1, v2);
#endif
#ifdef MAX_REDUCTION
        return max(v1, v2);
#endif

    return 0;
}

void Load(uint groupThreadID, uint globalThreadID, uint groupID, uint reductionBufferSize) {
#ifdef DOUBLE_LOAD // Reduction #4 -- Slide 18

    uint tid = groupThreadID;
    uint i = groupID * (reductionBufferSize * 2) + groupThreadID;

    gs_Reduce[tid] = ReductionOperator(_InputBuffer[i], _InputBuffer[i + reductionBufferSize]);

#else

    gs_Reduce[groupThreadID] = _InputBuffer[globalThreadID];

#endif

    AllMemoryBarrierWithGroupSync();

}

void Reduce(uint id, uint bufferSize) {
#ifdef INTERLEAVED_ADDRESSING_DIVERGENT // Reduction #1 -- Slide 9 (PROBLEM: Divergent branch in loop)
    
    for (uint s = 1; s < bufferSize; s *= 2) { 
        if (id % (2 * s) == 0) {
            float3 v = gs_Reduce[id];
            gs_Reduce[id] = ReductionOperator(v, gs_Reduce[id + s]);
        }

        GroupMemoryBarrierWithGroupSync();
    }

#endif
#ifdef INTERLEAVED_ADDRESSING_BANK_CONFLICT // Reduction #2 -- Slide 11 (PROBLEM: Different threads reference the same shared memory index)

    for (uint s = 1; s < bufferSize; s *= 2) {
        uint index = 2 * s * id;

        if (index < bufferSize) {
            float3 v = gs_Reduce[index];
            gs_Reduce[index] = ReductionOperator(v, gs_Reduce[index + s]);
        }

        GroupMemoryBarrierWithGroupSync();
    }

#endif
#ifdef SEQUENTIAL_ADDRESSING // Reduction #3 -- Slide 15 (PROBLEM: Half the threads of the warp are idle while the other half does work)

    for (uint s = bufferSize / 2; s > 0; s >>= 1) {
        if (id < s) {
            float3 v = gs_Reduce[id];
            gs_Reduce[id] = ReductionOperator(v, gs_Reduce[id + s]);
        }
        GroupMemoryBarrierWithGroupSync();
    }

#endif
}

[numthreads(REDUCTION_GROUP_SIZE, 1, 1)]
void GlobalReduce(uint3 id : SV_DISPATCHTHREADID, uint3 gtid : SV_GroupThreadID, uint3 gid : SV_GROUPID) {
    Load(gtid.x, id.x, gid.x, REDUCTION_GROUP_SIZE);

    Reduce(gtid.x, REDUCTION_GROUP_SIZE);

    if (gtid.x == 0) {
        _OutputBuffer[gid.x] = gs_Reduce[0];
    }
}

[numthreads(REDUCTION_GROUP_SIZE, 1, 1)]
void FinalReduce(uint3 id : SV_DISPATCHTHREADID, uint3 gtid : SV_GroupThreadID, uint3 gid : SV_GROUPID) {
    Load(id.x, id.x, gid.x, _ReductionBufferSize);

    Reduce(id.x, _ReductionBufferSize);

    if (id.x == 0) {
        #ifdef MIN_REDUCTION
        _OutputBuffer[0] = gs_Reduce[0];
        #endif
        #ifdef MAX_REDUCTION
        _OutputBuffer[1] = gs_Reduce[0];
        #endif
    }
}