#pragma kernel SingleThreadedScan
#pragma kernel SingleGroupMinReduce
#pragma kernel SingleGroupMaxReduce
#pragma kernel MultiGroupMinReduce
#pragma kernel MultiGroupMaxReduce

RWStructuredBuffer<float3> _OutputBuffer, _InputBuffer;
uint _ReductionBufferSize;

[numthreads(1, 1, 1)]
void SingleThreadedScan(uint3 id : SV_DISPATCHTHREADID) {
    float3 minPos = 1000000000000000.0f;
    float3 maxPos = -1000000000000000.0f;

    for (uint i = 0; i < _ReductionBufferSize; ++i) {
        float3 v = _InputBuffer[i];

        minPos = min(minPos, v);
        maxPos = max(maxPos, v);
    }

    if (id.x == 0) {
        _OutputBuffer[0] = minPos;
        _OutputBuffer[1] = maxPos;
    }
}

#define REDUCTION_GROUP_SIZE 128

#define MIN_REDUCTION 0
#define MAX_REDUCTION 1

#define INTERLEAVED_ADDRESSING_DIVERGENT 0
#define INTERLEAVED_ADDRESSING_BANK_CONFLICT 1
#define SEQUENTIAL_ADDRESSING 2

#define REDUCTION_METHOD SEQUENTIAL_ADDRESSING

groupshared float3 gs_Reduce[REDUCTION_GROUP_SIZE * 2];

void Load(uint gid, uint id) {
    gs_Reduce[gid] = _InputBuffer[id];

    AllMemoryBarrierWithGroupSync();

}

float3 ReductionOperator(uint operation, float3 v1, float3 v2) {
    if (operation == MIN_REDUCTION) {
        return min(v1, v2);
    } 
    if (operation == MAX_REDUCTION) {
        return max(v1, v2);
    }

    return 0;
}

// Reduction kernels and optimization progression referenced from https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf

void Reduce(uint operation, uint id, uint bufferSize) {
    #if REDUCTION_METHOD == INTERLEAVED_ADDRESSING_DIVERGENT // Reduction #1 -- Slide 9 (PROBLEM: Divergent branch in loop)
    for (uint s = 1; s < bufferSize; s *= 2) { 
        if (id % (2 * s) == 0) {
            float3 v = gs_Reduce[id];
            gs_Reduce[id] = ReductionOperator(operation, v, gs_Reduce[id + s]);
        }

        GroupMemoryBarrierWithGroupSync();
    }
    #elif REDUCTION_METHOD == INTERLEAVED_ADDRESSING_BANK_CONFLICT // Reduction #2 -- Slide 11 (PROBLEM: Different threads reference the same shared memory index)
    for (uint s = 1; s < bufferSize; s *= 2) {
        uint index = 2 * s * id;

        if (index < bufferSize) {
            float3 v = gs_Reduce[id];
            gs_Reduce[id] = ReductionOperator(operation, v, gs_Reduce[id + s]);
        }

        GroupMemoryBarrierWithGroupSync();
    }
    #elif REDUCTION_METHOD == SEQUENTIAL_ADDRESSING // Reduction #3 -- Slide 15 (PROBLEM: Half the threads of the warp are idle while the other half does work)
    for (uint s = bufferSize / 2; s > 0; s >>= 1) {
        if (id < s) {
            float3 v = gs_Reduce[id];
            gs_Reduce[id] = ReductionOperator(operation, v, gs_Reduce[id + s]);
        }
        GroupMemoryBarrierWithGroupSync();
    }
    #endif
}


[numthreads(REDUCTION_GROUP_SIZE, 1, 1)]
void SingleGroupMinReduce(uint3 id : SV_DISPATCHTHREADID, uint3 gtid : SV_GroupThreadID, uint3 gid : SV_GROUPID) {
    Load(id.x, id.x);

    Reduce(MIN_REDUCTION, id.x, _ReductionBufferSize);

    if (id.x == 0) {
        _OutputBuffer[0] = gs_Reduce[0];
    }
}

[numthreads(REDUCTION_GROUP_SIZE, 1, 1)]
void SingleGroupMaxReduce(uint3 id : SV_DISPATCHTHREADID, uint3 gtid : SV_GroupThreadID, uint3 gid : SV_GROUPID) {
    Load(id.x, id.x);

    Reduce(MAX_REDUCTION, id.x, _ReductionBufferSize);

    if (id.x == 0) {
        _OutputBuffer[1] = gs_Reduce[0];
    }
}

[numthreads(REDUCTION_GROUP_SIZE, 1, 1)]
void MultiGroupMinReduce(uint3 id : SV_DISPATCHTHREADID, uint3 gtid : SV_GroupThreadID, uint3 gid : SV_GROUPID) {
    Load(gtid.x, id.x);

    Reduce(MIN_REDUCTION, gtid.x, REDUCTION_GROUP_SIZE);

    if (gtid.x == 0) {
        _OutputBuffer[gid.x] = gs_Reduce[0];
    }
}

[numthreads(REDUCTION_GROUP_SIZE, 1, 1)]
void MultiGroupMaxReduce(uint3 id : SV_DISPATCHTHREADID, uint3 gtid : SV_GroupThreadID, uint3 gid : SV_GROUPID) {
    Load(gtid.x, id.x);

    Reduce(MAX_REDUCTION, gtid.x, REDUCTION_GROUP_SIZE);

    if (gtid.x == 0) {
        _OutputBuffer[gid.x] = gs_Reduce[0];
    }
}